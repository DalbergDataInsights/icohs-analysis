{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import timeit\n",
    "import scipy\n",
    "import datetime\n",
    "\n",
    "from scipy import stats\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../../data/input/dhis2/new_system/'\n",
    "input_path_old = '../../data/input/dhis2/old_system/'\n",
    "\n",
    "shapes_path = '../../data/shapes/district/districts_17_19_clean.shp'\n",
    "facility_path = '../../data/input/hospitals/original_data/'\n",
    "pop_path = '../../data/input/demographics/'\n",
    "\n",
    "output_path = '../../data/output/sprint3_analysis/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch my data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dict of names to replace district names\n",
    "\n",
    "district_name_dict = {'SEMBABULE': 'SSEMBABULE', 'MADI-OKOLLO': 'MADI OKOLLO', 'LUWEERO':'LUWERO'}\n",
    "\n",
    "# Get the district correposnding to facility ids\n",
    "\n",
    "xls = ExcelFile('../../data/input/dhis2/new_old_correspondance.xlsx')\n",
    "df_dis = xls.parse(xls.sheet_names[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a small fucntion to split the string column name of the data download as pivot \n",
    "\n",
    "def split(strng, sep, occ):\n",
    "    strng = strng.split(sep)\n",
    "    return sep.join(strng[occ[1]:]), sep.join(strng[:occ[0]]), sep.join(strng[occ[0]:occ[1]])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean the data downloaded in a pivot format\n",
    "\n",
    "def get_clean_stack(df,drop):\n",
    "\n",
    "    df['district']=df['orgunitlevel3'].apply(lambda x: x[:-9].upper())\n",
    "    df['district'].replace(district_name_dict,inplace=True)\n",
    "    \n",
    "    df.set_index(['district','organisationunitid'],drop=True,inplace=True)\n",
    "    \n",
    "    cols = np.arange(0,9)\n",
    "    df.drop(df.columns[cols],axis=1,inplace=True)\n",
    "    \n",
    "    cols = df.columns\n",
    "    new_cols=[]\n",
    "    for col in cols:\n",
    "        new_cols.append(split(col,' ',[-2,-1]))\n",
    "    df.columns=pd.MultiIndex.from_tuples(new_cols,names=['year','indic','month'])\n",
    "    \n",
    "    if drop != None:\n",
    "        df.drop(drop,axis=1,inplace=True,level=2)\n",
    "    \n",
    "    df1=df.copy().stack(level=[0,1,2],dropna=False).reset_index()\n",
    "    df1.rename(columns={0:'value'},inplace=True)\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean the data downloaded in a slightly different pivot format\n",
    "\n",
    "def get_clean_stack_newlayout(df,drop):\n",
    "\n",
    "    month_dict={'01':'Jan','02':'Feb','03':'Mar','04':'Apr',\n",
    "                '05':'May','06':'Jun','07':'Jul','08':'Aug',\n",
    "                '09':'Sep','10':'Oct','11':'Nov','12':'Dec'}\n",
    "    \n",
    "    df['district']=df['orgunitlevel3'].apply(lambda x: x[:-9].upper())\n",
    "    df['district'].replace(district_name_dict,inplace=True)\n",
    "\n",
    "    df['year']=df['periodcode'].astype('str').apply(lambda x: x[:4])\n",
    "    df['month']=df['periodcode'].astype('str').apply(lambda x: x[-2:]).replace(month_dict)\n",
    "    \n",
    "    if drop != None:\n",
    "        if type(drop)==str:\n",
    "            df1=df[~(df['month']==drop)].copy()\n",
    "        if type(drop)==list:\n",
    "            df1=df[~df['month'].isin(drop)].copy()\n",
    "    else:\n",
    "        df1=df.copy()\n",
    "        \n",
    "    df1.set_index(['district','organisationunitid','year','month'],drop=True,inplace=True)\n",
    "        \n",
    "    cols = np.arange(0,12)\n",
    "    df1.drop(df1.columns[cols],axis=1,inplace=True)\n",
    "    \n",
    "    df2=df1.copy().stack(dropna=False).reset_index()\n",
    "    df2.rename(columns={0:'value','level_4':'indic'},inplace=True)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To clean the data downloaded in a pivot format\n",
    "\n",
    "def get_clean_stack_api(df):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    df=pd.merge(df,df_dis[['id','district']],how='left',left_on='orgUnit',right_on='id')\n",
    "    \n",
    "    month_dict={'01':'Jan','02':'Feb','03':'Mar','04':'Apr',\n",
    "                '05':'May','06':'Jun','07':'Jul','08':'Aug',\n",
    "                '09':'Sep','10':'Oct','11':'Nov','12':'Dec'}\n",
    "    \n",
    "    df['year']=df['period'].astype('str').apply(lambda x: x[:4])\n",
    "    df['month']=df['period'].astype('str').apply(lambda x: x[-2:]).replace(month_dict)\n",
    "    \n",
    "    df.rename(columns={'orgUnit':'organisationunitid','dataElement':'indic'},inplace=True)\n",
    "    df.drop(['period','id'],axis=1,inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all the new data files together\n",
    "def fetch_new_data (filepaths,filepaths_no_dec,filepaths_newlayout,filepaths_api):\n",
    "    df = pd.DataFrame(columns = ['district', 'organisationunitid', 'year', 'indic', 'month', 'value'])\n",
    "    for x in filepaths:\n",
    "        x_df=get_clean_stack(pd.read_csv(x),drop='Dec')\n",
    "        df=pd.concat([df,x_df])\n",
    "    for x in filepaths_no_dec:\n",
    "        x_df=get_clean_stack(pd.read_csv(x),drop=None)\n",
    "        df=pd.concat([df,x_df])\n",
    "    for x in filepaths_newlayout:\n",
    "        x_df=get_clean_stack_newlayout(pd.read_csv(x),drop='Dec')\n",
    "        df=pd.concat([df,x_df])\n",
    "    for x in filepaths_api:\n",
    "        x_df=get_clean_stack_api(pd.read_csv(x))\n",
    "        df=pd.concat([df,x_df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dalberg\\anaconda3\\envs\\icohs\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# creating the new data stack\n",
    "\n",
    "filepaths = [input_path+'new_epi_data_by_facility.csv',\n",
    "            input_path+'new_mnch_data_by_facility.csv',\n",
    "            input_path+'new_sam_data_by_facility.csv',\n",
    "            input_path+'new_lbw_data_by_facility.csv',\n",
    "            input_path+'new_vitamin_data_by_facility.csv']\n",
    "\n",
    "filepaths_no_dec = [input_path+'may_new_sam_data_by_facility.csv',\n",
    "                    input_path+'may_new_epi_data_by_facility.csv']\n",
    "\n",
    "filepaths_newlayout = [input_path+'new_reporting_by_facility.csv',\n",
    "                       input_path+'new_epi_data_addendum_by_facility.csv',\n",
    "                       input_path+'may_new_mnch_data_by_facility.csv',\n",
    "                       input_path+'new_opd_ipd_data_by_facility.csv',\n",
    "                       input_path+'/mal/new_mal_cases_by_facility.csv',\n",
    "                       input_path+'/mal/new_mal_tested_by_facility.csv',\n",
    "                       input_path+'/mal/new_mal_treated_by_facility.csv']\n",
    "\n",
    "filepaths_api = [input_path+\"/hiv/HIV_newInstance.csv\"]\n",
    "\n",
    "new_stack = fetch_new_data (filepaths=filepaths,\n",
    "                            filepaths_no_dec=filepaths_no_dec,\n",
    "                            filepaths_newlayout=filepaths_newlayout,\n",
    "                            filepaths_api=filepaths_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old data\n",
    "\n",
    "For now extremely messy, had to be done bit by bit in random order, so quite some cleaning needed Ill do here, than put all into one nice file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all the old data files together\n",
    "def fetch_old_data (filepaths,filepaths_newlayout,filepaths_api):\n",
    "    df = pd.DataFrame(columns = ['district', 'organisationunitid', 'year', 'indic', 'month', 'value'])\n",
    "    for x in filepaths:\n",
    "        x_df=get_clean_stack(pd.read_csv(x),drop=None)\n",
    "        df=pd.concat([df,x_df])\n",
    "    for x in filepaths_newlayout:\n",
    "        x_df=get_clean_stack_newlayout(pd.read_csv(x),drop=None)\n",
    "        df=pd.concat([df,x_df])\n",
    "    for x in filepaths_api:\n",
    "        x_df=get_clean_stack_api(pd.read_csv(x))\n",
    "        df=pd.concat([df,x_df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dalberg\\anaconda3\\envs\\icohs\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: DtypeWarning: Columns (7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creating the old data stack\n",
    "\n",
    "# For now a bit all over the placedue to download limitations \n",
    "\n",
    "filepaths = [input_path_old+\"/epi/EPI - BCG doses given.csv\",\n",
    "             input_path_old+\"/epi/EPI - DPT-HepB-HIB 1 doses given.csv\",\n",
    "             input_path_old+\"/epi/EPI - DPT-HepB-HIB 3 doses given.csv\",\n",
    "             input_path_old+\"/epi/EPI - PCV 1 doses given.csv\",\n",
    "             input_path_old+\"/epi/EPI - PCV 3 doses given.csv\",\n",
    "             input_path_old+\"/epi/EPI - MR 1 doses given.csv\",\n",
    "             input_path_old+'/mat/admission_newborn.csv',\n",
    "             input_path_old+'/mat/ANC1_ANC4.csv',\n",
    "             input_path_old+'/mat/births.csv',\n",
    "             input_path_old+'/sam/lbw.csv',\n",
    "             input_path_old+'/sam/sam_mam.csv',\n",
    "             input_path_old+'/sam/lbw_abs.csv',\n",
    "             input_path_old+'/sam/vitamin.csv']\n",
    "\n",
    "filepaths_newlayout = [input_path_old + '/reporting/old_reporting_by_facility.csv',\n",
    "                      input_path_old + '/epi/EPI - TT doses given.csv',\n",
    "                      input_path_old + '/epi/EPI - HPV doses given.csv',\n",
    "                      input_path_old + 'ipd_opd/ipd_opd.csv',\n",
    "                      input_path_old + 'hiv/old_hiv_general.csv',\n",
    "                      input_path_old + 'mal/old_mal_data.csv']\n",
    "\n",
    "filepaths_api =[input_path_old + 'hiv/HIV_oldInstance.csv']\n",
    "\n",
    "old_stack = fetch_old_data (filepaths=filepaths,filepaths_newlayout=filepaths_newlayout,filepaths_api=filepaths_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv(pop_path+'UBOS_pop_proj_2015-25.csv')\n",
    "\n",
    "def get_clean_pop_pivot(pop):\n",
    "    pop['District']=pop['District'].apply(lambda x: x.upper())\n",
    "    pop['District'].replace(district_name_dict,inplace=True)\n",
    "\n",
    "    pop['age']= pop['Single Years'].apply(lambda x: ' '.join(x.split(' ')[:1]))\n",
    "    pop['age'].replace({'80+':'80'},inplace=True)\n",
    "    pop['age']=pop['age'].astype('int')\n",
    "    \n",
    "    pop.drop(['Single Years','Male','Female','Year2','FY'],axis=1,inplace=True)\n",
    "    \n",
    "    pop_pivot=pop.pivot_table(index=['District','Year'], columns=['age'])\n",
    "    \n",
    "    pop_pivot.columns = pop_pivot.columns.droplevel(0)\n",
    "    \n",
    "    pop_pivot.reset_index(inplace=True,drop=False)\n",
    "    \n",
    "    return pop_pivot\n",
    "\n",
    "pop_pivot=get_clean_pop_pivot(pop)\n",
    "pop_totals=pop_pivot.groupby('Year').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_pop_data():\n",
    "    from pandas import ExcelWriter\n",
    "    with ExcelWriter(output_path+'static_data.xlsx',mode='a') as writer:\n",
    "        pop_pivot.to_excel(writer,sheet_name='pop_age_year')\n",
    "        pop_totals.to_excel(writer,sheet_name='pop_total_age_year')\n",
    "#export_pop_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation and initial cleaning to be able to link up old and new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var_add_dict={'Babies Born with low birth weight (<2.5Kgs)':['105-MA04b2. Deliveries in unit -Live births - less than 2.5kg',\n",
    "                                                                 '105-MA04c2. Deliveries in unit - Fresh still birth - less than 2.5kg',\n",
    "                                                                 '105-MA04d2. Deliveries in unit - Macerated still birth - less than 2.5kg'],\n",
    "                  \n",
    "                  'td1':['EPI - Td1_Dose1_Child Bearing Age', \n",
    "                         'EPI - Td1_Dose1_Pregnant Women'],\n",
    "                  \n",
    "                  'td2':['EPI - Td2_Dose2_Child Bearing Age', \n",
    "                         'EPI - Td2_Dose2_Pregnant Women'],\n",
    "                  \n",
    "                  'td3':['EPI - Td3_Dose3_Child Bearing Age', \n",
    "                         'EPI - Td3_Dose3_Pregnant Women'],\n",
    "                  \n",
    "                  'td4_5':['EPI - Td4_Dose4_Child Bearing Age',\n",
    "                           'EPI - Td4_Dose4_Pregnant Women',\n",
    "                           'EPI - Td5_Dose5_Child Bearing Age',\n",
    "                           'EPI - Td5_Dose5_Pregnant Women'],\n",
    "                  \n",
    "                  'OPD attendance':['105-OA01. New attendance',\n",
    "                                    '105-OA02. Re-attendance'],\n",
    "                  \n",
    "                  'pregnant women tested for HIV in labor':['105-MA15a. Women tested for HIV in labour 1st time this Pregnancy - Total (TR & TRR)',\n",
    "                                                            '105-MA16a. Women re-tested for HIV in labour - Total (TR & TRR)'],\n",
    "                  \n",
    "                  'pregnant women tested HIV+ve in labor':['105-MA15b. Women tested for HIV in labour 1st time this Pregnancy - HIV+ (TRR)',\n",
    "                                                           '105-MA16b. Women re-tested for HIV in labour - HIV+ (TRR+)'],\n",
    "                  \n",
    "                  'malaria cases treated':['033B-MA06. Not tested cases treated',\n",
    "                                           '033B-MA07. RDT Negative Cases Treated',\n",
    "                                           '033B-MA08. RDT Positive Cases Treated',\n",
    "                                           '033B-MA09. Microscopy Negative Cases Treated',\n",
    "                                           '033B-MA10. Microscopy Positive Cases Treated'],\n",
    "                  \n",
    "                  'malaria tests':['033B-MA02. Cases Tested with RDT',\n",
    "                                   '033B-MA04. Cases Tested with Microscopy']}\n",
    "\n",
    "\n",
    "old_var_add_dict={'td4_5':['EPI - TT 4 doses given', \n",
    "                           'EPI - TT 5 doses given'],\n",
    "                  \n",
    "                  'OPD attendance':['105-1.1 OPD New Attendance', \n",
    "                                    '105-1.1 OPD Re-Attendance'],\n",
    "                  \n",
    "                  'pregnant women tested for HIV in labor':['105-2.2a Women tested for HIV in labour (1st time this Pregnancy)',\n",
    "                                                          '105-2.2b Women tested for HIV in labour (Retest this Pregnancy)'],\n",
    "                  \n",
    "                  'pregnant women tested HIV+ve in labor':['105-2.2a Women testing HIV+ in labour (1st time this Pregnancy)',\n",
    "                                                         '105-2.2b Women testing HIV+ in labour (Retest this Pregnancy)'],\n",
    "                  \n",
    "                  'breastfeeding mothers tested HIV +ve in PNC':['105-2.3a Breastfeeding mothers newly testing HIV+(1st test)',\n",
    "                                                                '105-2.3b Breastfeeding mothers newly testing HIV+(retest)']}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stack_add=new_stack.pivot_table(index=['district', 'organisationunitid', 'year','month'],columns='indic',values='value').copy()\n",
    "\n",
    "for x in new_var_add_dict.keys():\n",
    "    new_stack_add[x]=new_stack_add[new_var_add_dict[x]].sum(axis=1)\n",
    "\n",
    "new_stack_add=new_stack_add[list(new_var_add_dict.keys())].stack().reset_index()\n",
    "new_stack_add.rename(columns={0:'value'},inplace=True)\n",
    "new_stack=pd.concat([new_stack,new_stack_add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_stack_add=old_stack.pivot_table(index=['district', 'organisationunitid', 'year','month'],columns='indic',values='value').copy()\n",
    "\n",
    "for x in old_var_add_dict.keys():\n",
    "    old_stack_add[x]=old_stack_add[old_var_add_dict[x]].sum(axis=1)\n",
    "\n",
    "old_stack_add=old_stack_add[list(old_var_add_dict.keys())].stack().reset_index()\n",
    "old_stack_add.rename(columns={0:'value'},inplace=True)\n",
    "old_stack=pd.concat([old_stack,old_stack_add])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean a data issue in the old stack regarding reporting rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_stack['value'] = np.where(old_stack['indic'].isin(['HMIS 105:1 Actual reports','HMIS 105:1 Expected reports'])\n",
    "                              & (old_stack['value']==4),1,old_stack['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIP : Create a new variable aggregating MUAC and W/L SAM and MAM indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a subset of indicators to merge on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done in Excel manually, after running the small function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_var_names():\n",
    "    from pandas import ExcelWriter\n",
    "    with ExcelWriter('../../data/input/dhis2/new_old_correspondance.xlsx',mode='a') as writer:\n",
    "        pd.Series(old_stack['indic'].unique()).to_excel(writer,sheet_name='old_vars')\n",
    "        pd.Series(new_stack['indic'].unique()).to_excel(writer,sheet_name='new_vars')\n",
    "\n",
    "export_var_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I get back the result into a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_var_names():\n",
    "    from pandas import ExcelFile\n",
    "    xls = ExcelFile('../../data/input/dhis2/new_old_correspondance.xlsx')\n",
    "    df = xls.parse(xls.sheet_names[0])\n",
    "    df.set_index('Old',drop=True,inplace=True)\n",
    "    old_new_dict=df['New'].to_dict()\n",
    "    old_stack.replace({'indic': old_new_dict},inplace=True) # Replacing the old names by the new\n",
    "    target_indics=list(old_new_dict.values()) # Store my target indicators\n",
    "    return target_indics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_indics=replace_var_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['105-AN01a. ANC 1st Visit for women',\n",
       " '105-AN02. ANC 4th Visit for women',\n",
       " '105-MA01. Admissions',\n",
       " '105-MA04a. Deliveries in unit - Total',\n",
       " '105-MA04b1. Deliveries in unit -Live births - Total',\n",
       " '105-MA04c1. Deliveries in unit - Fresh still birth - Total',\n",
       " '105-MA04d1. Deliveries in unit - Macerated still birth - Total',\n",
       " '105-MA11. Newborn deaths (0-7 days)',\n",
       " '105-PN01a. Post Natal Attendances - Mother',\n",
       " 'EPI - BCG doses given',\n",
       " 'EPI - DPT-HepB-HIB 1 doses given',\n",
       " 'EPI - DPT-HepB-HIB 3 doses given',\n",
       " 'EPI - MR 1 doses given',\n",
       " 'EPI - PCV 1 doses_Under 1',\n",
       " 'EPI - PCV 3 doses_Under 1',\n",
       " '105-NA03a1. Identified malnourished clients(<10) this month - MAM using MUAC',\n",
       " '105-NA03e1. Identified malnourished clients(<10) this month - SAM With Oedema',\n",
       " '105-NA03c1. Identified malnourished clients(<10) this month - SAM using MUAC -  Without Oedema',\n",
       " '105-CH01. Vit A supplement (1st Dose)',\n",
       " '105-CH02. Vit A supplement (2nd Dose)',\n",
       " 'Babies Born with low birth weight (<2.5Kgs)',\n",
       " 'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Actual reports 1. National',\n",
       " 'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Expected reports 1. National',\n",
       " 'EPI - HPV1 doses given',\n",
       " 'EPI - HPV2 doses given',\n",
       " 'td1',\n",
       " 'td2',\n",
       " 'td3',\n",
       " 'td4_5',\n",
       " 'OPD attendance',\n",
       " '108-CI02. No. of admissions',\n",
       " '105-HT03a1. Total Tested for HIV',\n",
       " '105-HT03a2. Total New HIV+',\n",
       " '105-HT03a3. Total Linked to HIV Care',\n",
       " '105-AN29a. Pregnant women newly tested for HIV in this pregnancy at any ANC visit (TR & TRR) - total',\n",
       " '105-AN30a. Pregnant Women tested HIV+ for 1st time this pregnancy (TRR) at any ANC Visit - Total',\n",
       " '105-AN32. HIV+ pregnant women initiated on ART for eMTCT at any visit irrespective of when tested HIV+ (TRR, TRR+,TRR‚àö)',\n",
       " 'pregnant women tested for HIV in labor',\n",
       " 'pregnant women tested HIV+ve in labor',\n",
       " '105-MA17. Women initiating ART in maternity - HIV+',\n",
       " '105-PN03a. Breastfeedng mothers tested for HIV 1st time during Postnatal - Total (TR & TRR)',\n",
       " '105-PN03b. Breastfeedng mothers tested for HIV 1st time during Postnatal - TRR',\n",
       " '105-PN05a. HIV+ women initiating ART in Postnatal - Total',\n",
       " '033B-CD01b. Malaria (diagnosed) - Deaths',\n",
       " 'malaria cases treated',\n",
       " '033B-CD01a. Malaria (diagnosed)  - Cases',\n",
       " 'malaria tests']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_indics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check there is no issue with facility ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the valid ids\n",
    "\n",
    "old_ids=set(old_stack['organisationunitid'].unique())\n",
    "new_ids=set(new_stack['organisationunitid'].unique())\n",
    "valid_ids=list(old_ids.intersection(new_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get only the bits of data I am interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_stack_t=old_stack[old_stack['indic'].isin(target_indics) & old_stack['organisationunitid'].isin(valid_ids)].copy()\n",
    "new_stack_t=new_stack[new_stack['indic'].isin(target_indics) & new_stack['organisationunitid'].isin(valid_ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>organisationunitid</th>\n",
       "      <th>year</th>\n",
       "      <th>indic</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Apr</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Aug</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Dec</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Feb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Jan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  district organisationunitid  year                  indic month  value\n",
       "0    ZOMBO        XikHv88zzDn  2018  EPI - BCG doses given   Apr    7.0\n",
       "1    ZOMBO        XikHv88zzDn  2018  EPI - BCG doses given   Aug    7.0\n",
       "2    ZOMBO        XikHv88zzDn  2018  EPI - BCG doses given   Dec    5.0\n",
       "3    ZOMBO        XikHv88zzDn  2018  EPI - BCG doses given   Feb    NaN\n",
       "4    ZOMBO        XikHv88zzDn  2018  EPI - BCG doses given   Jan    NaN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_t=pd.concat([old_stack_t,new_stack_t])\n",
    "stack_t.reset_index(drop=True,inplace=True)\n",
    "stack_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EPI - BCG doses given', 'EPI - DPT-HepB-HIB 1 doses given',\n",
       "       'EPI - DPT-HepB-HIB 3 doses given', 'EPI - PCV 1 doses_Under 1',\n",
       "       'EPI - PCV 3 doses_Under 1', 'EPI - MR 1 doses given',\n",
       "       '105-MA01. Admissions', '105-MA04a. Deliveries in unit - Total',\n",
       "       '105-PN01a. Post Natal Attendances - Mother',\n",
       "       '105-AN01a. ANC 1st Visit for women',\n",
       "       '105-AN02. ANC 4th Visit for women',\n",
       "       '105-MA04b1. Deliveries in unit -Live births - Total',\n",
       "       '105-MA04c1. Deliveries in unit - Fresh still birth - Total',\n",
       "       '105-MA04d1. Deliveries in unit - Macerated still birth - Total',\n",
       "       '105-MA11. Newborn deaths (0-7 days)',\n",
       "       '105-NA03a1. Identified malnourished clients(<10) this month - MAM using MUAC',\n",
       "       '105-NA03e1. Identified malnourished clients(<10) this month - SAM With Oedema',\n",
       "       '105-NA03c1. Identified malnourished clients(<10) this month - SAM using MUAC -  Without Oedema',\n",
       "       'Babies Born with low birth weight (<2.5Kgs)',\n",
       "       '105-CH01. Vit A supplement (1st Dose)',\n",
       "       '105-CH02. Vit A supplement (2nd Dose)',\n",
       "       'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Actual reports 1. National',\n",
       "       'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Expected reports 1. National',\n",
       "       'td1', 'td2', 'td3', 'EPI - HPV1 doses given',\n",
       "       'EPI - HPV2 doses given', '108-CI02. No. of admissions',\n",
       "       '105-HT03a1. Total Tested for HIV', '105-HT03a2. Total New HIV+',\n",
       "       '105-HT03a3. Total Linked to HIV Care',\n",
       "       '033B-CD01a. Malaria (diagnosed)  - Cases',\n",
       "       '033B-CD01b. Malaria (diagnosed) - Deaths', 'malaria tests',\n",
       "       'malaria cases treated',\n",
       "       '105-AN32. HIV+ pregnant women initiated on ART for eMTCT at any visit irrespective of when tested HIV+ (TRR, TRR+,TRR‚àö)',\n",
       "       '105-AN29a. Pregnant women newly tested for HIV in this pregnancy at any ANC visit (TR & TRR) - total',\n",
       "       '105-AN30a. Pregnant Women tested HIV+ for 1st time this pregnancy (TRR) at any ANC Visit - Total',\n",
       "       '105-MA17. Women initiating ART in maternity - HIV+',\n",
       "       '105-PN05a. HIV+ women initiating ART in Postnatal - Total',\n",
       "       '105-PN03a. Breastfeedng mothers tested for HIV 1st time during Postnatal - Total (TR & TRR)',\n",
       "       'td4_5', 'OPD attendance',\n",
       "       'pregnant women tested for HIV in labor',\n",
       "       'pregnant women tested HIV+ve in labor',\n",
       "       '105-PN03b. Breastfeedng mothers tested for HIV 1st time during Postnatal - TRR'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_t['indic'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split reporting vars from others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_indics=['HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Actual reports 1. National',\n",
    "               'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Expected reports 1. National']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_t_noreport=stack_t[~stack_t['indic'].isin(report_indics)].copy()\n",
    "stack_t_report=stack_t[stack_t['indic'].isin(report_indics)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flag outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put our data in the right format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def pivot_stack(df):\n",
    "    pivot_outliers=df.copy().pivot_table(index=['district', 'organisationunitid', 'indic'], columns=['year','month' ]) #,dropna=False)\n",
    "    pivot_outliers.rename(columns={'value':'with_outiers'},level=0,inplace=True)\n",
    "    pivot_outliers.columns.rename('type', level=0, inplace=True)\n",
    "    pivot_outliers.dropna(how='all',axis=0,inplace=True) # looks like there is no all na line to drop\n",
    "    return pivot_outliers\n",
    "\n",
    "pivot_outliers=pivot_stack(stack_t_noreport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace outliers using a std deviation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data in the right format\n",
    "\n",
    "def replace_outliers(pivot_outliers,cutoff):#df\n",
    "    \n",
    "    pivot_no_outliers=pd.DataFrame(columns=pivot_outliers.columns,index=pivot_outliers.index)\n",
    "    pivot_no_outliers.rename(columns={'with_outiers':'without_outliers'},level=0,inplace=True)\n",
    "    \n",
    "    for x in pivot_outliers.index: # to exclude\n",
    "        values = pivot_outliers.loc[x,:].values\n",
    "        if np.nanstd(values)!=0 and np.isnan(values).sum()!=len(values):\n",
    "            zscore = abs(stats.zscore(values,nan_policy='omit'))\n",
    "            new_values = np.where(zscore>cutoff,np.nanmedian(values),values)\n",
    "\n",
    "        else:\n",
    "            new_values = values\n",
    "\n",
    "        pivot_no_outliers.iloc[pivot_outliers.index.get_loc(x),:] = new_values.astype('float')\n",
    "\n",
    "    return pivot_no_outliers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-34eb04742e5b>:12: RuntimeWarning: invalid value encountered in greater\n",
      "  new_values = np.where(zscore>cutoff,np.nanmedian(values),values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pivot_no_outliers = replace_outliers(pivot_outliers,cutoff=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data in the right format\n",
    "\n",
    "def replace_outliers_iqr(pivot_outliers,k):#df\n",
    "    \n",
    "    pivot_no_outliers=pd.DataFrame(columns=pivot_outliers.columns,index=pivot_outliers.index)\n",
    "    pivot_no_outliers.rename(columns={'with_outiers':'without_outliers'},level=0,inplace=True)\n",
    "    \n",
    "    for x in pivot_outliers.index:\n",
    "        values = pivot_outliers.loc[x,:].values\n",
    "        if np.nanstd(values)!=0 and np.isnan(values).sum()!=len(values):\n",
    "            Q1 = np.nanquantile(values,0.25)\n",
    "            Q3 = np.nanquantile(values,0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            LB = Q1 - k*IQR\n",
    "            UB = Q3 + k*IQR\n",
    "            new_values = np.where((values<LB)|(values>UB),np.nanmedian(values),values)\n",
    "\n",
    "        else:\n",
    "            new_values = values\n",
    "\n",
    "        pivot_no_outliers.iloc[pivot_outliers.index.get_loc(x),:] = new_values.astype('float')\n",
    "\n",
    "    return pivot_no_outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-53464bcc185b>:16: RuntimeWarning: invalid value encountered in less\n",
      "  new_values = np.where((values<LB)|(values>UB),np.nanmedian(values),values)\n",
      "<ipython-input-35-53464bcc185b>:16: RuntimeWarning: invalid value encountered in greater\n",
      "  new_values = np.where((values<LB)|(values>UB),np.nanmedian(values),values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pivot_no_outliers_iqr = replace_outliers_iqr(pivot_outliers,k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack the outlier corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_stack(pivot):\n",
    "    stack = pivot.stack(level=[0,1,2],dropna=False).reset_index()\n",
    "    stack.rename(columns={0:'value'},inplace=True)\n",
    "    stack.drop('type',axis=1,inplace=True)\n",
    "    stack['value']=stack['value'].astype(dtype='float64')\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_t_noout=pivot_stack(pivot_no_outliers)\n",
    "stack_t_noout_iqr=pivot_stack(pivot_no_outliers_iqr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record which data points were changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_compare = pd.merge(stack_t,stack_t_noout,how='inner',\n",
    "                           left_on=['district', 'organisationunitid', 'year', 'indic', 'month'],\n",
    "                           right_on=['district', 'organisationunitid', 'year', 'indic', 'month']).rename(columns={'value_x':'value_out','value_y':'value_noout'})\n",
    "stack_compare.dropna(subset=['value_out','value_noout'],inplace=True)\n",
    "stack_compare['changed']=np.where((stack_compare['value_out'] != stack_compare['value_noout']),True,False)\n",
    "changed = stack_compare[stack_compare['changed']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_compare_iqr = pd.merge(stack_t,stack_t_noout_iqr,how='inner',\n",
    "                           left_on=['district', 'organisationunitid', 'year', 'indic', 'month'],\n",
    "                           right_on=['district', 'organisationunitid', 'year', 'indic', 'month']).rename(columns={'value_x':'value_out','value_y':'value_noout'})\n",
    "stack_compare_iqr.dropna(subset=['value_out','value_noout'],inplace=True)\n",
    "stack_compare_iqr['changed']=np.where((stack_compare_iqr['value_out'] != stack_compare_iqr['value_noout']),True,False)\n",
    "changed_iqr = stack_compare_iqr[stack_compare_iqr['changed']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>organisationunitid</th>\n",
       "      <th>year</th>\n",
       "      <th>indic</th>\n",
       "      <th>month</th>\n",
       "      <th>value_out</th>\n",
       "      <th>value_noout</th>\n",
       "      <th>changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LUWERO</td>\n",
       "      <td>T4M9UgfqV5q</td>\n",
       "      <td>2019</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Jul</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>PADER</td>\n",
       "      <td>auzuV39xOTU</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Oct</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>AMURIA</td>\n",
       "      <td>o7CJeTwDapk</td>\n",
       "      <td>2019</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Feb</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>MOYO</td>\n",
       "      <td>ZubUtSX9erU</td>\n",
       "      <td>2019</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Jan</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>ABIM</td>\n",
       "      <td>ltIECAx2ppI</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Dec</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541607</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2020</td>\n",
       "      <td>td4_5</td>\n",
       "      <td>Feb</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541617</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2020</td>\n",
       "      <td>td4_5</td>\n",
       "      <td>Jan</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541637</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2020</td>\n",
       "      <td>td4_5</td>\n",
       "      <td>May</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541645</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>aTH1dUHop5k</td>\n",
       "      <td>2020</td>\n",
       "      <td>td2</td>\n",
       "      <td>Apr</td>\n",
       "      <td>103.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541675</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>aTH1dUHop5k</td>\n",
       "      <td>2020</td>\n",
       "      <td>td2</td>\n",
       "      <td>Mar</td>\n",
       "      <td>120.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74667 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        district organisationunitid  year                  indic month  \\\n",
       "41        LUWERO        T4M9UgfqV5q  2019  EPI - BCG doses given   Jul   \n",
       "394        PADER        auzuV39xOTU  2018  EPI - BCG doses given   Oct   \n",
       "831       AMURIA        o7CJeTwDapk  2019  EPI - BCG doses given   Feb   \n",
       "928         MOYO        ZubUtSX9erU  2019  EPI - BCG doses given   Jan   \n",
       "1010        ABIM        ltIECAx2ppI  2018  EPI - BCG doses given   Dec   \n",
       "...          ...                ...   ...                    ...   ...   \n",
       "5541607    ZOMBO        XikHv88zzDn  2020                  td4_5   Feb   \n",
       "5541617    ZOMBO        XikHv88zzDn  2020                  td4_5   Jan   \n",
       "5541637    ZOMBO        XikHv88zzDn  2020                  td4_5   May   \n",
       "5541645    ZOMBO        aTH1dUHop5k  2020                    td2   Apr   \n",
       "5541675    ZOMBO        aTH1dUHop5k  2020                    td2   Mar   \n",
       "\n",
       "         value_out  value_noout  changed  \n",
       "41            44.0         22.0     True  \n",
       "394           58.0         12.0     True  \n",
       "831           20.0          4.0     True  \n",
       "928            6.0          2.0     True  \n",
       "1010          57.0          7.0     True  \n",
       "...            ...          ...      ...  \n",
       "5541607       15.0          0.0     True  \n",
       "5541617       11.0          0.0     True  \n",
       "5541637       11.0          0.0     True  \n",
       "5541645      103.0         19.0     True  \n",
       "5541675      120.0         19.0     True  \n",
       "\n",
       "[74667 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed.to_csv(output_path+'outliers_list.csv')\n",
    "changed_iqr.to_csv(output_path+'outliers_list_iqr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export this to Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check any data point below:\n",
    "\n",
    "#stack_t[(stack_t['organisationunitid']=='JO1cLIghdBv') & \n",
    "        #(stack_t['year']=='2018') & \n",
    "        #(stack_t['indic']=='105-NA03e1. Identified malnourished clients(<10) this month - SAM With Oedema') & \n",
    "        #(stack_t['month']=='Apr')]['value'].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put together my DHIS data with and without outlier\n",
    "\n",
    "fac_stack_final = pd.merge(stack_t_noreport,stack_t_noout,how='left',\n",
    "                           left_on=['district', 'organisationunitid', 'year', 'indic', 'month'],\n",
    "                           right_on=['district', 'organisationunitid', 'year', 'indic', 'month']).rename(columns={'value_x':'value_out','value_y':'value_noout'})\n",
    "\n",
    "fac_stack_final = pd.merge(fac_stack_final,stack_t_noout_iqr,how='left',\n",
    "                           left_on=['district', 'organisationunitid', 'year', 'indic', 'month'],\n",
    "                           right_on=['district', 'organisationunitid', 'year', 'indic', 'month']).rename(columns={'value':'value_noout_iqr'})\n",
    "\n",
    "# Make a note of whcih facilities reported which didt \n",
    "\n",
    "fac_stack_final['reported'] = (fac_stack_final['value_out']>0).astype('int')\n",
    "\n",
    "# Add in the reporting rate data, that did not go through theoutlier precocedure\n",
    "\n",
    "stack_t_report.rename(columns={'value':'reported'},inplace=True)\n",
    "stack_t_report.set_index(['district','organisationunitid','year' ,'indic','month'],inplace=True,drop=True)\n",
    "#stack_t_report = stack_t_report.loc[~stack_t_report.index.duplicated(keep='first')] # Note here a weird issue of duplicates \n",
    "stack_t_report.reset_index(inplace=True)\n",
    "\n",
    "#Puts it all together \n",
    "\n",
    "fac_stack_final=pd.concat([stack_t_report,fac_stack_final],ignore_index=True)\n",
    "\n",
    "# Create a pivot\n",
    "\n",
    "fac_pivot_final=fac_stack_final.pivot_table(index=['district','organisationunitid','year','month'], columns=['indic'],aggfunc=max)\n",
    "fac_pivot_final=fac_pivot_final.stack(level=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_export=fac_pivot_final.copy()\n",
    "pivot_export.to_csv(output_path+'corrected_data_facility.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the code for our framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name_dict={'district':'id', \n",
    "               'date':'date',\n",
    "               'organisationunitid':'facility_id', \n",
    "               'level_4':'type',\n",
    "               '105-AN01a. ANC 1st Visit for women':'1st ANC Visits',\n",
    "               '105-AN02. ANC 4th Visit for women':'4th ANC Visits',\n",
    "               '105-MA01. Admissions' : 'Maternity Admissions',\n",
    "               '105-MA04a. Deliveries in unit - Total': 'Deliveries in unit',\n",
    "               '105-MA04b1. Deliveries in unit -Live births - Total': 'Deliveries in unit - live',\n",
    "               '105-MA04c1. Deliveries in unit - Fresh still birth - Total': 'Deliveries in unit - fresh stillbirth',\n",
    "               '105-MA04d1. Deliveries in unit - Macerated still birth - Total': 'Deliveries in unit - macerated stillbirth',\n",
    "               '105-MA11. Newborn deaths (0-7 days)':'Newborn deaths',\n",
    "               '105-NA03a1. Identified malnourished clients(<10) this month - MAM using MUAC' : 'MAM identified - MUAC',\n",
    "               '105-NA03c1. Identified malnourished clients(<10) this month - SAM using MUAC -  Without Oedema':'SAM identified no oedema- MUAC',\n",
    "               '105-NA03e1. Identified malnourished clients(<10) this month - SAM With Oedema':'SAM identified oedema- MUAC',\n",
    "               '105-PN01a. Post Natal Attendances - Mother':'Postnatal Visits',\n",
    "               'Babies Born with low birth weight (<2.5Kgs)' : 'Low weigh births', \n",
    "               '105-CH01. Vit A supplement (1st Dose)' : 'Vitamin A 1st dose',\n",
    "               '105-CH02. Vit A supplement (2nd Dose)': 'Vitamin A 2nd dose', \n",
    "               'EPI - BCG doses given' : 'BCG',\n",
    "               'EPI - DPT-HepB-HIB 1 doses given':'DPT1', \n",
    "               'EPI - DPT-HepB-HIB 3 doses given':'DPT3',\n",
    "               'EPI - HPV1 doses given':'HPV1', \n",
    "               'EPI - HPV2 doses given':'HPV2',\n",
    "               'EPI - MR 1 doses given':'MR1', \n",
    "               'EPI - PCV 1 doses_Under 1':'PCV1',\n",
    "               'EPI - PCV 3 doses_Under 1':'PCV3',\n",
    "               'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Actual reports 1. National' : 'Actual 105:1 reporting',\n",
    "               'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Expected reports 1. National': 'Expected 105:1 reporting',\n",
    "               'td1':'TD1', \n",
    "               'td2':'TD2', \n",
    "               'td3':'TD3', \n",
    "               'td4_5':'TD4-5'}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DATA PROCESSING: Clean the data into desired formats\n",
    "\n",
    "data=pivot_export.reset_index()\n",
    "\n",
    "# a. Combine the date into one column and format\n",
    "\n",
    "dates = []\n",
    "for index, row in data.iterrows():\n",
    "    dates.append(str(row['year']) + '-' + row['month'])\n",
    "data['date'] = dates\n",
    "\n",
    "def parse_date(date):\n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    year, month = date.split('-')\n",
    "    month = months.index(month)+1\n",
    "    return datetime.date(year=int(year), month=month, day=1)\n",
    "\n",
    "data['date'] = data.date.apply(parse_date)\n",
    "data['date'] = pd.to_datetime(data.date)\n",
    "\n",
    "# b. Select and rename the metric columns\n",
    "\n",
    "data = data[list(var_name_dict.keys())]\n",
    "data.columns = list(var_name_dict.values())\n",
    "data.head()\n",
    "\n",
    "# c. Get dataset of data grouped according to regions and years\n",
    "data_2018 = data[(data.date.dt.year == 2018) & (data.date.dt.month == 3)]\n",
    "data_2019 = data[(data.date.dt.year == 2019) & (data.date.dt.month == 3)]\n",
    "data_2019 = data_2019.groupby('id').sum()\n",
    "data_2018 = data_2018.groupby('id').sum()\n",
    "data_yrs_reg = pd.merge(data_2018, data_2019, on='id',\n",
    "                        suffixes=(' 2018', ' 2019'))\n",
    "data_yrs_reg.head()\n",
    "\n",
    "# d. Get dataset of change between years\n",
    "for col in list(var_name_dict.values())[4:]:\n",
    "    data_yrs_reg[col] = round(\n",
    "        ((data_yrs_reg[f'{col} 2019'] - data_yrs_reg[f'{col} 2018']) / data_yrs_reg[f'{col} 2018'])*100, 2)\n",
    "data_change_reg = data_yrs_reg.reset_index()#[['id', '1st ANC Visits', '4th ANC Visits',\n",
    "                                              #'Maternity Admissions', 'Postnatal Visits', '3rd Dose DTaP-HB-IPV-Hib', '1st Dose MR']]\n",
    "data_change_reg.head()\n",
    "\n",
    "# e. Get dataset of data grouped according to date (on national level)\n",
    "data_date = data.groupby('date').sum()\n",
    "data_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_data_reporting = data[data['type']=='reported']\n",
    "facility_data_with_outliers = data[data['type']=='value_out']\n",
    "facility_data_no_outliers_std = data[data['type']=='value_noout']\n",
    "facility_data_no_outliers_iqr = data[data['type']=='value_noout_iqr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_data_reporting.to_csv(output_path+'facility_data_reporting.csv')\n",
    "facility_data_with_outliers.to_csv(output_path+'facility_data_with_outliers.csv')\n",
    "facility_data_no_outliers_std.to_csv(output_path+'facility_data_no_outliers_std.csv')\n",
    "facility_data_no_outliers_iqr.to_csv(output_path+'facility_data_no_outliers_iqr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
