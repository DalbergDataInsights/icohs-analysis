{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import timeit\n",
    "import scipy\n",
    "\n",
    "from scipy import stats\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../../data/input/dhis2/new_system/'\n",
    "input_path_old = '../../data/input/dhis2/old_system/'\n",
    "\n",
    "shapes_path = '../../data/shapes/district/districts_17_19_clean.shp'\n",
    "facility_path = '../../data/input/hospitals/original_data/'\n",
    "pop_path = '../../data/input/demographics/'\n",
    "\n",
    "output_path = '../../data/output/sprint3_analysis/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch my data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a small fucntion to split the string column name of the data download as pivot \n",
    "\n",
    "def split(strng, sep, occ):\n",
    "    strng = strng.split(sep)\n",
    "    return sep.join(strng[occ[1]:]), sep.join(strng[:occ[0]]), sep.join(strng[occ[0]:occ[1]])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dict of names to replace district names\n",
    "\n",
    "district_name_dict = {'SEMBABULE': 'SSEMBABULE', 'MADI-OKOLLO': 'MADI OKOLLO', 'LUWEERO':'LUWERO'}\n",
    "\n",
    "# For a fully automated one, will need to do fuzzy matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean the data downloaded in a pivot format\n",
    "\n",
    "def get_clean_stack(df,drop):\n",
    "\n",
    "    df['district']=df['orgunitlevel3'].apply(lambda x: x[:-9].upper())\n",
    "    df['district'].replace(district_name_dict,inplace=True)\n",
    "    \n",
    "    df.set_index(['district','organisationunitid'],drop=True,inplace=True)\n",
    "    \n",
    "    cols = np.arange(0,9)\n",
    "    df.drop(df.columns[cols],axis=1,inplace=True)\n",
    "    \n",
    "    cols = df.columns\n",
    "    new_cols=[]\n",
    "    for col in cols:\n",
    "        new_cols.append(split(col,' ',[-2,-1]))\n",
    "    df.columns=pd.MultiIndex.from_tuples(new_cols,names=['year','indic','month'])\n",
    "    \n",
    "    if drop != None:\n",
    "        df.drop(drop,axis=1,inplace=True,level=2)\n",
    "    \n",
    "    df1=df.copy().stack(level=[0,1,2],dropna=False).reset_index()\n",
    "    df1.rename(columns={0:'value'},inplace=True)\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean the data downloaded in a slightly different pivot format\n",
    "\n",
    "def get_clean_stack_newlayout(df,drop):\n",
    "\n",
    "    month_dict={'01':'Jan','02':'Feb','03':'Mar','04':'Apr',\n",
    "                '05':'May','06':'Jun','07':'Jul','08':'Aug',\n",
    "                '09':'Sep','10':'Oct','11':'Nov','12':'Dec'}\n",
    "    \n",
    "    df['district']=df['orgunitlevel3'].apply(lambda x: x[:-9].upper())\n",
    "    df['district'].replace(district_name_dict,inplace=True)\n",
    "\n",
    "    df['year']=df['periodcode'].astype('str').apply(lambda x: x[:4])\n",
    "    df['month']=df['periodcode'].astype('str').apply(lambda x: x[-2:]).replace(month_dict)\n",
    "    \n",
    "    if drop != None:\n",
    "        if type(drop)==str:\n",
    "            df1=df[~(df['month']==drop)].copy()\n",
    "        if type(drop)==list:\n",
    "            df1=df[~df['month'].isin(drop)].copy()\n",
    "    else:\n",
    "        df1=df.copy()\n",
    "        \n",
    "    df1.set_index(['district','organisationunitid','year','month'],drop=True,inplace=True)\n",
    "        \n",
    "    cols = np.arange(0,12)\n",
    "    df1.drop(df1.columns[cols],axis=1,inplace=True)\n",
    "    \n",
    "    df2=df1.copy().stack(dropna=False).reset_index()\n",
    "    df2.rename(columns={0:'value','level_4':'indic'},inplace=True)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all the new data files together\n",
    "def fetch_new_data (filepaths,filepaths_no_dec,filepaths_newlayout):\n",
    "    df = pd.DataFrame(columns = ['district', 'organisationunitid', 'year', 'indic', 'month', 'value'])\n",
    "    for x in filepaths:\n",
    "        x_df=get_clean_stack(pd.read_csv(x),drop='Dec')\n",
    "        df=pd.concat([df,x_df])\n",
    "    for x in filepaths_no_dec:\n",
    "        x_df=get_clean_stack(pd.read_csv(x),drop=None)\n",
    "        df=pd.concat([df,x_df])\n",
    "    for x in filepaths_newlayout:\n",
    "        x_df=get_clean_stack_newlayout(pd.read_csv(x),drop='Dec')\n",
    "        df=pd.concat([df,x_df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dalberg\\anaconda3\\envs\\icohs\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# creating the new data stack\n",
    "\n",
    "filepaths = [input_path+'new_epi_data_by_facility.csv',\n",
    "            input_path+'new_mnch_data_by_facility.csv',\n",
    "            input_path+'new_sam_data_by_facility.csv',\n",
    "            input_path+'new_lbw_data_by_facility.csv',\n",
    "            input_path+'new_vitamin_data_by_facility.csv']\n",
    "\n",
    "filepaths_no_dec = [input_path+'may_new_sam_data_by_facility.csv',\n",
    "                    input_path+'may_new_epi_data_by_facility.csv']\n",
    "\n",
    "filepaths_newlayout = [input_path+'new_reporting_by_facility.csv',\n",
    "                      input_path+'new_epi_data_addendum_by_facility.csv']\n",
    "\n",
    "new_stack = fetch_new_data (filepaths=filepaths,filepaths_no_dec=filepaths_no_dec,filepaths_newlayout=filepaths_newlayout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old data\n",
    "\n",
    "For now extremely messy, had to be done bit by bit in random order, so quite some cleaning needed Ill do here, than put all into one nice file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all the old data files together\n",
    "def fetch_old_data (filepaths,filepaths_newlayout):\n",
    "    df = pd.DataFrame(columns = ['district', 'organisationunitid', 'year', 'indic', 'month', 'value'])\n",
    "    for x in filepaths:\n",
    "        x_df=get_clean_stack(pd.read_csv(x),drop=None)\n",
    "        df=pd.concat([df,x_df])\n",
    "    for x in filepaths_newlayout:\n",
    "        x_df=get_clean_stack_newlayout(pd.read_csv(x),drop=None)\n",
    "        df=pd.concat([df,x_df])    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dalberg\\anaconda3\\envs\\icohs\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: DtypeWarning: Columns (7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creating the old data stack\n",
    "\n",
    "# For now a bit all over the placedue to download limitations \n",
    "\n",
    "filepaths = [input_path_old+\"/epi/EPI - BCG doses given.csv\",\n",
    "             input_path_old+\"/epi/EPI - DPT-HepB-HIB 1 doses given.csv\",\n",
    "             input_path_old+\"/epi/EPI - DPT-HepB-HIB 3 doses given.csv\",\n",
    "             input_path_old+\"/epi/EPI - PCV 1 doses given.csv\",\n",
    "             input_path_old+\"/epi/EPI - PCV 3 doses given.csv\",\n",
    "             input_path_old+\"/epi/EPI - MR 1 doses given.csv\",\n",
    "             input_path_old+'/mat/admission_newborn.csv',\n",
    "             input_path_old+'/mat/ANC1_ANC4.csv',\n",
    "             input_path_old+'/mat/births.csv',\n",
    "             input_path_old+'/sam/lbw.csv',\n",
    "             input_path_old+'/sam/sam_mam.csv',\n",
    "             input_path_old+'/sam/lbw_abs.csv',\n",
    "             input_path_old+'/sam/vitamin.csv']\n",
    "\n",
    "filepaths_newlayout = [input_path_old + 'old_reporting_by_facility.csv',\n",
    "                      input_path_old + '/epi/EPI - TT doses given.csv',\n",
    "                      input_path_old + '/epi/EPI - HPV doses given.csv']\n",
    "\n",
    "old_stack = fetch_old_data (filepaths=filepaths,filepaths_newlayout=filepaths_newlayout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv(pop_path+'UBOS_pop_proj_2015-25.csv')\n",
    "\n",
    "def get_clean_pop_pivot(pop):\n",
    "    pop['District']=pop['District'].apply(lambda x: x.upper())\n",
    "    pop['District'].replace(district_name_dict,inplace=True)\n",
    "\n",
    "    pop['age']= pop['Single Years'].apply(lambda x: ' '.join(x.split(' ')[:1]))\n",
    "    pop['age'].replace({'80+':'80'},inplace=True)\n",
    "    pop['age']=pop['age'].astype('int')\n",
    "    \n",
    "    pop.drop(['Single Years','Male','Female','Year2','FY'],axis=1,inplace=True)\n",
    "    \n",
    "    pop_pivot=pop.pivot_table(index=['District','Year'], columns=['age'])\n",
    "    \n",
    "    pop_pivot.columns = pop_pivot.columns.droplevel(0)\n",
    "    \n",
    "    pop_pivot.reset_index(inplace=True,drop=False)\n",
    "    \n",
    "    return pop_pivot\n",
    "\n",
    "pop_pivot=get_clean_pop_pivot(pop)\n",
    "pop_totals=pop_pivot.groupby('Year').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_pop_data():\n",
    "    from pandas import ExcelWriter\n",
    "    with ExcelWriter(output_path+'static_data.xlsx',mode='a') as writer:\n",
    "        pop_pivot.to_excel(writer,sheet_name='pop_age_year')\n",
    "        pop_totals.to_excel(writer,sheet_name='pop_total_age_year')\n",
    "#export_pop_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation and initial cleaning to be able to link up old and new datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new variable aggregating lbw indicators for the new database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbw_elements = ['105-MA04b2. Deliveries in unit -Live births - less than 2.5kg',\n",
    "                '105-MA04c2. Deliveries in unit - Fresh still birth - less than 2.5kg',\n",
    "                '105-MA04d2. Deliveries in unit - Macerated still birth - less than 2.5kg']\n",
    "\n",
    "def all_nan_sum(x):\n",
    "    y=x.values\n",
    "    if np.isnan(y).sum()==len(y):\n",
    "        x=np.nan\n",
    "    else:\n",
    "        x=np.nansum(y)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>organisationunitid</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "      <th>indic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABIM</td>\n",
       "      <td>JO1cLIghdBv</td>\n",
       "      <td>2020</td>\n",
       "      <td>Apr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Babies Born with low birth weight (&lt;2.5Kgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABIM</td>\n",
       "      <td>JO1cLIghdBv</td>\n",
       "      <td>2020</td>\n",
       "      <td>Feb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Babies Born with low birth weight (&lt;2.5Kgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABIM</td>\n",
       "      <td>JO1cLIghdBv</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Babies Born with low birth weight (&lt;2.5Kgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABIM</td>\n",
       "      <td>JO1cLIghdBv</td>\n",
       "      <td>2020</td>\n",
       "      <td>Mar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Babies Born with low birth weight (&lt;2.5Kgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABIM</td>\n",
       "      <td>JO1cLIghdBv</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Babies Born with low birth weight (&lt;2.5Kgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38215</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>xrqX9NsoWWe</td>\n",
       "      <td>2020</td>\n",
       "      <td>Apr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Babies Born with low birth weight (&lt;2.5Kgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38216</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>xrqX9NsoWWe</td>\n",
       "      <td>2020</td>\n",
       "      <td>Feb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Babies Born with low birth weight (&lt;2.5Kgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38217</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>xrqX9NsoWWe</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Babies Born with low birth weight (&lt;2.5Kgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38218</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>xrqX9NsoWWe</td>\n",
       "      <td>2020</td>\n",
       "      <td>Mar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Babies Born with low birth weight (&lt;2.5Kgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38219</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>xrqX9NsoWWe</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Babies Born with low birth weight (&lt;2.5Kgs)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38220 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      district organisationunitid  year month  value  \\\n",
       "0         ABIM        JO1cLIghdBv  2020   Apr    0.0   \n",
       "1         ABIM        JO1cLIghdBv  2020   Feb    NaN   \n",
       "2         ABIM        JO1cLIghdBv  2020   Jan    0.0   \n",
       "3         ABIM        JO1cLIghdBv  2020   Mar    0.0   \n",
       "4         ABIM        JO1cLIghdBv  2020   May    0.0   \n",
       "...        ...                ...   ...   ...    ...   \n",
       "38215    ZOMBO        xrqX9NsoWWe  2020   Apr    NaN   \n",
       "38216    ZOMBO        xrqX9NsoWWe  2020   Feb    NaN   \n",
       "38217    ZOMBO        xrqX9NsoWWe  2020   Jan    NaN   \n",
       "38218    ZOMBO        xrqX9NsoWWe  2020   Mar    NaN   \n",
       "38219    ZOMBO        xrqX9NsoWWe  2020   May    NaN   \n",
       "\n",
       "                                             indic  \n",
       "0      Babies Born with low birth weight (<2.5Kgs)  \n",
       "1      Babies Born with low birth weight (<2.5Kgs)  \n",
       "2      Babies Born with low birth weight (<2.5Kgs)  \n",
       "3      Babies Born with low birth weight (<2.5Kgs)  \n",
       "4      Babies Born with low birth weight (<2.5Kgs)  \n",
       "...                                            ...  \n",
       "38215  Babies Born with low birth weight (<2.5Kgs)  \n",
       "38216  Babies Born with low birth weight (<2.5Kgs)  \n",
       "38217  Babies Born with low birth weight (<2.5Kgs)  \n",
       "38218  Babies Born with low birth weight (<2.5Kgs)  \n",
       "38219  Babies Born with low birth weight (<2.5Kgs)  \n",
       "\n",
       "[38220 rows x 6 columns]"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbw_data = new_stack[new_stack['indic'].isin(lbw_elements)].set_index(['district', \n",
    "                                                                       'organisationunitid',\n",
    "                                                                       'indic',\n",
    "                                                                       'year',\n",
    "                                                                       'month'])['value'].groupby(['district', \n",
    "                                                                                                   'organisationunitid',\n",
    "                                                                                                   'year',\n",
    "                                                                                                   'month']).apply(all_nan_sum)\n",
    "lbw_data=lbw_data.reset_index()\n",
    "lbw_data['indic']='Babies Born with low birth weight (<2.5Kgs)'\n",
    "lbw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stack=pd.concat([new_stack,lbw_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean a data issue in the old stack regarding reporting rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_stack['value'] = np.where(old_stack['indic'].isin(['HMIS 105:1 Actual reports','HMIS 105:1 Expected reports'])\n",
    "                              & (old_stack['value']==4),1,old_stack['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new variable aggregating MUAC and W/L SAM and MAM indicators\n",
    "\n",
    "WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the TD doses and create new aggregate variables to link up old and new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_td_indics=['EPI - Td1_Dose1_Child Bearing Age', 'EPI - Td1_Dose1_Pregnant Women',\n",
    "               'EPI - Td2_Dose2_Child Bearing Age', 'EPI - Td2_Dose2_Pregnant Women',\n",
    "               'EPI - Td3_Dose3_Child Bearing Age', 'EPI - Td3_Dose3_Pregnant Women',\n",
    "               'EPI - Td4_Dose4_Child Bearing Age', 'EPI - Td4_Dose4_Pregnant Women',\n",
    "               'EPI - Td5_Dose5_Child Bearing Age', 'EPI - Td5_Dose5_Pregnant Women']\n",
    "\n",
    "new_td=new_stack.pivot_table(index=['district', 'organisationunitid', 'year','month'],columns='indic',values='value')[new_td_indics].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_td['td1'] = new_td[new_td_indics[0:2]].sum(axis=1)\n",
    "new_td['td2'] = new_td[new_td_indics[2:4]].sum(axis=1)\n",
    "new_td['td3'] = new_td[new_td_indics[4:6]].sum(axis=1)\n",
    "new_td['td4_5'] = new_td[new_td_indics[6:10]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_td_stack=new_td[['td1','td2','td3','td4_5']].stack().reset_index()\n",
    "new_td_stack.rename(columns={0:'value'},inplace=True)\n",
    "new_stack=pd.concat([new_stack,new_td_stack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_td_indics=['EPI - TT 1 doses given','EPI - TT 1 doses given Pregnant',\n",
    "               'EPI - TT 2 doses given','EPI - TT 2 doses given Pregnant', \n",
    "               'EPI - TT 3 doses given','EPI - TT 3 doses given Pregnant',\n",
    "               'EPI - TT 4 doses given','EPI - TT 4 doses given Pregnant',\n",
    "               'EPI - TT 5 doses given','EPI - TT 5 doses given Pregnant']\n",
    "\n",
    "old_td=old_stack.pivot_table(index=['district', 'organisationunitid', 'year','month'],columns='indic',values='value')[old_td_indics].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old_td['td1'] = old_td[old_td_indics[0:2]].sum(axis=1)\n",
    "#old_td['td2'] = old_td[old_td_indics[2:4]].sum(axis=1)\n",
    "#old_td['td3'] = old_td[old_td_indics[4:6]].sum(axis=1)\n",
    "old_td['td4_5'] = old_td[old_td_indics[6:10]].sum(axis=1)\n",
    "old_td['indic'] = 'td4_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_td_stack=old_td['td4_5'].reset_index()\n",
    "old_td_stack.rename(columns={'td4_5':'value'},inplace=True)\n",
    "old_stack=pd.concat([old_stack,old_td_stack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a subset of indicators to merge on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done in Excel manually, after running the small function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_var_names():\n",
    "    from pandas import ExcelWriter\n",
    "    with ExcelWriter('../../data/input/dhis2/new_old_correspondance.xlsx',mode='a') as writer:\n",
    "        pd.Series(old_stack['indic'].unique()).to_excel(writer,sheet_name='old_vars')\n",
    "        pd.Series(new_stack['indic'].unique()).to_excel(writer,sheet_name='new_vars')\n",
    "\n",
    "#export_var_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I get back the result into a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_var_names():\n",
    "    from pandas import ExcelFile\n",
    "    xls = ExcelFile('../../data/input/dhis2/new_old_correspondance.xlsx')\n",
    "    df = xls.parse(xls.sheet_names[0])\n",
    "    df.set_index('Old',drop=True,inplace=True)\n",
    "    old_new_dict=df['New'].to_dict()\n",
    "    old_stack.replace({'indic': old_new_dict},inplace=True) # Replacing the old names by the new\n",
    "    target_indics=list(old_new_dict.values()) # Store my target indicators\n",
    "    return target_indics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_indics=replace_var_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check there is no issue with facility ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the valid ids\n",
    "\n",
    "old_ids=set(old_stack['organisationunitid'].unique())\n",
    "new_ids=set(new_stack['organisationunitid'].unique())\n",
    "valid_ids=list(old_ids.intersection(new_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get only the bits of data I am interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_stack_t=old_stack[old_stack['indic'].isin(target_indics) & old_stack['organisationunitid'].isin(valid_ids)].copy()\n",
    "new_stack_t=new_stack[new_stack['indic'].isin(target_indics) & new_stack['organisationunitid'].isin(valid_ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>organisationunitid</th>\n",
       "      <th>year</th>\n",
       "      <th>indic</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Apr</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Aug</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Dec</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Feb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>XikHv88zzDn</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Jan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  district organisationunitid  year                  indic month  value\n",
       "0    ZOMBO        XikHv88zzDn  2018  EPI - BCG doses given   Apr    7.0\n",
       "1    ZOMBO        XikHv88zzDn  2018  EPI - BCG doses given   Aug    7.0\n",
       "2    ZOMBO        XikHv88zzDn  2018  EPI - BCG doses given   Dec    5.0\n",
       "3    ZOMBO        XikHv88zzDn  2018  EPI - BCG doses given   Feb    NaN\n",
       "4    ZOMBO        XikHv88zzDn  2018  EPI - BCG doses given   Jan    NaN"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_t=pd.concat([old_stack_t,new_stack_t])\n",
    "stack_t.reset_index(drop=True,inplace=True)\n",
    "stack_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split reporting vars from others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_indics=['HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Actual reports 1. National',\n",
    "               'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Expected reports 1. National']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_t_noreport=stack_t[~stack_t['indic'].isin(report_indics)].copy()\n",
    "stack_t_report=stack_t[stack_t['indic'].isin(report_indics)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flag outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put our data in the right format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def pivot_stack(df):\n",
    "    pivot_outliers=df.copy().pivot_table(index=['district', 'organisationunitid', 'indic'], columns=['year','month' ]) #,dropna=False)\n",
    "    pivot_outliers.rename(columns={'value':'with_outiers'},level=0,inplace=True)\n",
    "    pivot_outliers.columns.rename('type', level=0, inplace=True)\n",
    "    pivot_outliers.dropna(how='all',axis=0,inplace=True) # looks like there is no all na line to drop\n",
    "    return pivot_outliers\n",
    "\n",
    "pivot_outliers=pivot_stack(stack_t_noreport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace outliers using a std deviation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data in the right format\n",
    "\n",
    "def replace_outliers(pivot_outliers,cutoff):#df\n",
    "    \n",
    "    pivot_no_outliers=pd.DataFrame(columns=pivot_outliers.columns,index=pivot_outliers.index)\n",
    "    pivot_no_outliers.rename(columns={'with_outiers':'without_outliers'},level=0,inplace=True)\n",
    "    \n",
    "    for x in pivot_outliers.index: # to exclude\n",
    "        values = pivot_outliers.loc[x,:].values\n",
    "        if np.nanstd(values)!=0 and np.isnan(values).sum()!=len(values):\n",
    "            zscore = abs(stats.zscore(values,nan_policy='omit'))\n",
    "            new_values = np.where(zscore>cutoff,np.nanmedian(values),values)\n",
    "\n",
    "        else:\n",
    "            new_values = values\n",
    "\n",
    "        pivot_no_outliers.iloc[pivot_outliers.index.get_loc(x),:] = new_values.astype('float')\n",
    "\n",
    "    return pivot_no_outliers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-515-34eb04742e5b>:12: RuntimeWarning: invalid value encountered in greater\n",
      "  new_values = np.where(zscore>cutoff,np.nanmedian(values),values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pivot_no_outliers = replace_outliers(pivot_outliers,cutoff=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data in the right format\n",
    "\n",
    "def replace_outliers_iqr(pivot_outliers,k):#df\n",
    "    \n",
    "    pivot_no_outliers=pd.DataFrame(columns=pivot_outliers.columns,index=pivot_outliers.index)\n",
    "    pivot_no_outliers.rename(columns={'with_outiers':'without_outliers'},level=0,inplace=True)\n",
    "    \n",
    "    for x in pivot_outliers.index:\n",
    "        values = pivot_outliers.loc[x,:].values\n",
    "        if np.nanstd(values)!=0 and np.isnan(values).sum()!=len(values):\n",
    "            Q1 = np.nanquantile(values,0.25)\n",
    "            Q3 = np.nanquantile(values,0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            LB = Q1 - k*IQR\n",
    "            UB = Q3 + k*IQR\n",
    "            new_values = np.where((values<LB)|(values>UB),np.nanmedian(values),values)\n",
    "\n",
    "        else:\n",
    "            new_values = values\n",
    "\n",
    "        pivot_no_outliers.iloc[pivot_outliers.index.get_loc(x),:] = new_values.astype('float')\n",
    "\n",
    "    return pivot_no_outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-517-53464bcc185b>:16: RuntimeWarning: invalid value encountered in less\n",
      "  new_values = np.where((values<LB)|(values>UB),np.nanmedian(values),values)\n",
      "<ipython-input-517-53464bcc185b>:16: RuntimeWarning: invalid value encountered in greater\n",
      "  new_values = np.where((values<LB)|(values>UB),np.nanmedian(values),values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pivot_no_outliers_iqr = replace_outliers_iqr(pivot_outliers,k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack the outlier corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_stack(pivot):\n",
    "    stack = pivot.stack(level=[0,1,2],dropna=False).reset_index()\n",
    "    stack.rename(columns={0:'value'},inplace=True)\n",
    "    stack.drop('type',axis=1,inplace=True)\n",
    "    stack['value']=stack['value'].astype(dtype='float64')\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_t_noout=pivot_stack(pivot_no_outliers)\n",
    "stack_t_noout_iqr=pivot_stack(pivot_no_outliers_iqr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record which data points were changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_compare = pd.merge(stack_t,stack_t_noout,how='inner',\n",
    "                           left_on=['district', 'organisationunitid', 'year', 'indic', 'month'],\n",
    "                           right_on=['district', 'organisationunitid', 'year', 'indic', 'month']).rename(columns={'value_x':'value_out','value_y':'value_noout'})\n",
    "stack_compare.dropna(subset=['value_out','value_noout'],inplace=True)\n",
    "stack_compare['changed']=np.where((stack_compare['value_out'] != stack_compare['value_noout']),True,False)\n",
    "changed = stack_compare[stack_compare['changed']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_compare_iqr = pd.merge(stack_t,stack_t_noout_iqr,how='inner',\n",
    "                           left_on=['district', 'organisationunitid', 'year', 'indic', 'month'],\n",
    "                           right_on=['district', 'organisationunitid', 'year', 'indic', 'month']).rename(columns={'value_x':'value_out','value_y':'value_noout'})\n",
    "stack_compare_iqr.dropna(subset=['value_out','value_noout'],inplace=True)\n",
    "stack_compare_iqr['changed']=np.where((stack_compare_iqr['value_out'] != stack_compare_iqr['value_noout']),True,False)\n",
    "changed_iqr = stack_compare_iqr[stack_compare_iqr['changed']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>organisationunitid</th>\n",
       "      <th>year</th>\n",
       "      <th>indic</th>\n",
       "      <th>month</th>\n",
       "      <th>value_out</th>\n",
       "      <th>value_noout</th>\n",
       "      <th>changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LUWERO</td>\n",
       "      <td>T4M9UgfqV5q</td>\n",
       "      <td>2019</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Jul</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>PADER</td>\n",
       "      <td>auzuV39xOTU</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Oct</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>AMURIA</td>\n",
       "      <td>o7CJeTwDapk</td>\n",
       "      <td>2019</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Feb</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>MOYO</td>\n",
       "      <td>ZubUtSX9erU</td>\n",
       "      <td>2019</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Jan</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>ABIM</td>\n",
       "      <td>ltIECAx2ppI</td>\n",
       "      <td>2018</td>\n",
       "      <td>EPI - BCG doses given</td>\n",
       "      <td>Dec</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067362</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>aTH1dUHop5k</td>\n",
       "      <td>2020</td>\n",
       "      <td>td2</td>\n",
       "      <td>Apr</td>\n",
       "      <td>103.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067374</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>aTH1dUHop5k</td>\n",
       "      <td>2020</td>\n",
       "      <td>td2</td>\n",
       "      <td>Mar</td>\n",
       "      <td>120.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067407</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>apEUhKfLxjY</td>\n",
       "      <td>2020</td>\n",
       "      <td>td3</td>\n",
       "      <td>Feb</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067432</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>eZC9Ddr4KIy</td>\n",
       "      <td>2020</td>\n",
       "      <td>td4_5</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067468</th>\n",
       "      <td>ZOMBO</td>\n",
       "      <td>tuYjF238GTf</td>\n",
       "      <td>2020</td>\n",
       "      <td>td4_5</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37875 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        district organisationunitid  year                  indic month  \\\n",
       "41        LUWERO        T4M9UgfqV5q  2019  EPI - BCG doses given   Jul   \n",
       "394        PADER        auzuV39xOTU  2018  EPI - BCG doses given   Oct   \n",
       "831       AMURIA        o7CJeTwDapk  2019  EPI - BCG doses given   Feb   \n",
       "928         MOYO        ZubUtSX9erU  2019  EPI - BCG doses given   Jan   \n",
       "1010        ABIM        ltIECAx2ppI  2018  EPI - BCG doses given   Dec   \n",
       "...          ...                ...   ...                    ...   ...   \n",
       "3067362    ZOMBO        aTH1dUHop5k  2020                    td2   Apr   \n",
       "3067374    ZOMBO        aTH1dUHop5k  2020                    td2   Mar   \n",
       "3067407    ZOMBO        apEUhKfLxjY  2020                    td3   Feb   \n",
       "3067432    ZOMBO        eZC9Ddr4KIy  2020                  td4_5   Jan   \n",
       "3067468    ZOMBO        tuYjF238GTf  2020                  td4_5   Feb   \n",
       "\n",
       "         value_out  value_noout  changed  \n",
       "41            44.0         22.0     True  \n",
       "394           58.0         12.0     True  \n",
       "831           20.0          4.0     True  \n",
       "928            6.0          2.0     True  \n",
       "1010          57.0          7.0     True  \n",
       "...            ...          ...      ...  \n",
       "3067362      103.0         19.0     True  \n",
       "3067374      120.0         19.0     True  \n",
       "3067407       21.0          1.0     True  \n",
       "3067432        1.0          0.0     True  \n",
       "3067468        1.0          0.0     True  \n",
       "\n",
       "[37875 rows x 8 columns]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed.to_csv(output_path+'outliers_list.csv')\n",
    "changed_iqr.to_csv(output_path+'outliers_list_iqr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export this to Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check any data point below:\n",
    "\n",
    "#stack_t[(stack_t['organisationunitid']=='JO1cLIghdBv') & \n",
    "        #(stack_t['year']=='2018') & \n",
    "        #(stack_t['indic']=='105-NA03e1. Identified malnourished clients(<10) this month - SAM With Oedema') & \n",
    "        #(stack_t['month']=='Apr')]['value'].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put together my DHIS data with and without outlier\n",
    "\n",
    "fac_stack_final = pd.merge(stack_t_noreport,stack_t_noout,how='left',\n",
    "                           left_on=['district', 'organisationunitid', 'year', 'indic', 'month'],\n",
    "                           right_on=['district', 'organisationunitid', 'year', 'indic', 'month']).rename(columns={'value_x':'value_out','value_y':'value_noout'})\n",
    "\n",
    "fac_stack_final = pd.merge(fac_stack_final,stack_t_noout_iqr,how='left',\n",
    "                           left_on=['district', 'organisationunitid', 'year', 'indic', 'month'],\n",
    "                           right_on=['district', 'organisationunitid', 'year', 'indic', 'month']).rename(columns={'value':'value_noout_iqr'})\n",
    "\n",
    "# Make a note of whcih facilities reported which didt \n",
    "\n",
    "fac_stack_final['reported'] = (fac_stack_final['value_out']>0).astype('int')\n",
    "\n",
    "# Add in the reporting rate data, that did not go through theoutlier precocedure\n",
    "\n",
    "stack_t_report.rename(columns={'value':'reported'},inplace=True)\n",
    "stack_t_report.set_index(['district','organisationunitid','year' ,'indic','month'],inplace=True,drop=True)\n",
    "#stack_t_report = stack_t_report.loc[~stack_t_report.index.duplicated(keep='first')] # Note here a weird issue of duplicates \n",
    "stack_t_report.reset_index(inplace=True)\n",
    "\n",
    "#Puts it all together \n",
    "\n",
    "fac_stack_final=pd.concat([stack_t_report,fac_stack_final],ignore_index=True)\n",
    "\n",
    "# Create a pivot\n",
    "\n",
    "fac_pivot_final=fac_stack_final.pivot_table(index=['district','organisationunitid','year','month'], columns=['indic'],aggfunc=max)\n",
    "fac_pivot_final=fac_pivot_final.stack(level=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_export=fac_pivot_final.copy()\n",
    "pivot_export.to_csv(output_path+'corrected_data_facility.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['district', 'organisationunitid', 'year', 'month', 'level_4',\n",
       "       '105-AN01a. ANC 1st Visit for women',\n",
       "       '105-AN02. ANC 4th Visit for women',\n",
       "       '105-CH01. Vit A supplement (1st Dose)',\n",
       "       '105-CH02. Vit A supplement (2nd Dose)', '105-MA01. Admissions',\n",
       "       '105-MA04a. Deliveries in unit - Total',\n",
       "       '105-MA04b1. Deliveries in unit -Live births - Total',\n",
       "       '105-MA04c1. Deliveries in unit - Fresh still birth - Total',\n",
       "       '105-MA04d1. Deliveries in unit - Macerated still birth - Total',\n",
       "       '105-MA11. Newborn deaths (0-7 days)',\n",
       "       '105-NA03a1. Identified malnourished clients(<10) this month - MAM using MUAC',\n",
       "       '105-NA03c1. Identified malnourished clients(<10) this month - SAM using MUAC -  Without Oedema',\n",
       "       '105-NA03e1. Identified malnourished clients(<10) this month - SAM With Oedema',\n",
       "       '105-PN01a. Post Natal Attendances - Mother',\n",
       "       'Babies Born with low birth weight (<2.5Kgs)', 'EPI - BCG doses given',\n",
       "       'EPI - DPT-HepB-HIB 1 doses given', 'EPI - DPT-HepB-HIB 3 doses given',\n",
       "       'EPI - HPV1 doses given', 'EPI - HPV2 doses given',\n",
       "       'EPI - MR 1 doses given', 'EPI - PCV 1 doses_Under 1',\n",
       "       'EPI - PCV 3 doses_Under 1',\n",
       "       'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Actual reports 1. National',\n",
       "       'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Expected reports 1. National',\n",
       "       'NUT: Percentage of children/babies born with low birth weight (<2.5kg)',\n",
       "       'td1', 'td2', 'td3', 'td4_5'],\n",
       "      dtype='object', name='indic')"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name_dict={'district':'id', \n",
    "               'date':'date',\n",
    "               'organisationunitid':'facility_id', \n",
    "               'level_4':'type',\n",
    "               '105-AN01a. ANC 1st Visit for women':'1st ANC Visits',\n",
    "               '105-AN02. ANC 4th Visit for women':'4th ANC Visits',\n",
    "               '105-MA01. Admissions' : 'Maternity Admissions',\n",
    "               '105-MA04a. Deliveries in unit - Total',\n",
    "               '105-MA04b1. Deliveries in unit -Live births - Total',\n",
    "               '105-MA04c1. Deliveries in unit - Fresh still birth - Total',\n",
    "               '105-MA04d1. Deliveries in unit - Macerated still birth - Total',\n",
    "               '105-MA11. Newborn deaths (0-7 days)',\n",
    "               '105-NA03a1. Identified malnourished clients(<10) this month - MAM using MUAC',\n",
    "               '105-NA03c1. Identified malnourished clients(<10) this month - SAM using MUAC -  Without Oedema',\n",
    "               '105-NA03e1. Identified malnourished clients(<10) this month - SAM With Oedema',\n",
    "               '105-PN01a. Post Natal Attendances - Mother':'Postnatal Visits',\n",
    "               'Babies Born with low birth weight (<2.5Kgs)', \n",
    "               'EPI - BCG doses given',\n",
    "               'EPI - DPT-HepB-HIB 1 doses given':'DPT1', \n",
    "               'EPI - DPT-HepB-HIB 3 doses given':'DPT3',\n",
    "               'EPI - HPV1 doses given':'HPV1', \n",
    "               'EPI - HPV2 doses given':'HPV2',\n",
    "               'EPI - MR 1 doses given':'MR1', \n",
    "               'EPI - PCV 1 doses_Under 1':'PCV1',\n",
    "               'EPI - PCV 3 doses_Under 1':'PCV3',\n",
    "               'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Actual reports 1. National',\n",
    "               'HMIS 105:01 - OPD Monthly Report (Attendance, Referrals, Conditions,TB, Nutrition) Expected reports 1. National',\n",
    "               'NUT: Percentage of children/babies born with low birth weight (<2.5kg)',\n",
    "               'td1':'TD1', \n",
    "               'td2':'TD2', \n",
    "               'td3':'TD3', \n",
    "               'td4_5':'TD4-5'}\n",
    "\n",
    "               '105-CH01. Vit A supplement (1st Dose)',\n",
    "               '105-CH02. Vit A supplement (2nd Dose)', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DATA PROCESSING: Clean the data into desired formats\n",
    "\n",
    "data=pivot_export.reset_index()\n",
    "\n",
    "# a. Combine the date into one column and format\n",
    "\n",
    "dates = []\n",
    "for index, row in data.iterrows():\n",
    "    dates.append(str(row['year']) + '-' + row['month'])\n",
    "data['date'] = dates\n",
    "\n",
    "def parse_date(date):\n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    year, month = date.split('-')\n",
    "    month = months.index(month)+1\n",
    "    return datetime(year=int(year), month=month, day=1)\n",
    "\n",
    "data['date'] = data.date.apply(parse_date)\n",
    "data['date'] = pd.to_datetime(data.date)\n",
    "\n",
    "# b. Select and rename the metric columns\n",
    "data = data[['district', 'date', '105-AN01a. ANC 1st Visit for women', '105-AN02. ANC 4th Visit for women', '105-MA01. Admissions',\n",
    "             '105-PN01a. Post Natal Attendances - Mother', 'EPI - DPT-HepB-HIB 3 doses given', 'EPI - MR 1 doses given']]\n",
    "data.columns = ['id', 'date', '1st ANC Visits', '4th ANC Visits',\n",
    "                'Maternity Admissions', 'Postnatal Visits', '3rd Dose DTaP-HB-IPV-Hib', '1st Dose MR']\n",
    "data.head()\n",
    "\n",
    "# c. Get dataset of data grouped according to regions and years\n",
    "data_2018 = data[(data.date.dt.year == 2018) & (data.date.dt.month == 3)]\n",
    "data_2019 = data[(data.date.dt.year == 2019) & (data.date.dt.month == 3)]\n",
    "data_2019 = data_2019.groupby('id').sum()\n",
    "data_2018 = data_2018.groupby('id').sum()\n",
    "data_yrs_reg = pd.merge(data_2018, data_2019, on='id',\n",
    "                        suffixes=(' 2018', ' 2019'))\n",
    "data_yrs_reg.head()\n",
    "\n",
    "# d. Get dataset of change between years\n",
    "for col in ['1st ANC Visits', '4th ANC Visits', 'Maternity Admissions', 'Postnatal Visits', '3rd Dose DTaP-HB-IPV-Hib', '1st Dose MR']:\n",
    "    data_yrs_reg[col] = round(\n",
    "        ((data_yrs_reg[f'{col} 2019'] - data_yrs_reg[f'{col} 2018']) / data_yrs_reg[f'{col} 2018'])*100, 2)\n",
    "data_yrs_reg['1st ANC Visits'] = round(\n",
    "    ((data_yrs_reg['1st ANC Visits 2019'] - data_yrs_reg['1st ANC Visits 2018']) / data_yrs_reg['1st ANC Visits 2018'])*100, 2)\n",
    "data_change_reg = data_yrs_reg.reset_index()[['id', '1st ANC Visits', '4th ANC Visits',\n",
    "                                              'Maternity Admissions', 'Postnatal Visits', '3rd Dose DTaP-HB-IPV-Hib', '1st Dose MR']]\n",
    "data_change_reg.head()\n",
    "\n",
    "# e. Get dataset of data grouped according to date (on national level)\n",
    "data_date = data.groupby('date').sum()\n",
    "data_date.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
